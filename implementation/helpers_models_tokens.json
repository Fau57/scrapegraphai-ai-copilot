[
    {
        "prompt": "how is models_tokens implemented in Scrapegraphai?",
        "answer": "\"\"\"\nModels token\n\"\"\"\n\nmodels_tokens = {\n    \"openai\": {\n        \"gpt-3.5-turbo-0125\": 16385,\n        \"gpt-3.5\": 4096,\n        \"gpt-3.5-turbo\": 4096,\n        \"gpt-3.5-turbo-1106\": 16385,\n        \"gpt-3.5-turbo-instruct\": 4096,\n        \"gpt-4-0125-preview\": 128000,\n        \"gpt-4-turbo-preview\": 128000,\n        \"gpt-4-turbo\": 128000,\n        \"gpt-4-turbo-2024-04-09\": 128000,\n        \"gpt-4-1106-preview\": 128000,\n        \"gpt-4-vision-preview\": 128000,\n        \"gpt-4\": 8192,\n        \"gpt-4-0613\": 8192,\n        \"gpt-4-32k\": 32768,\n        \"gpt-4-32k-0613\": 32768,\n        \"gpt-4o\": 128000,\n    },\n    \"azure\": {\n        \"gpt-3.5-turbo\": 4096,\n        \"gpt-4\": 8192,\n        \"gpt-4-0613\": 8192,\n        \"gpt-4-32k\": 32768,\n        \"gpt-4-32k-0613\": 32768,\n        \"gpt-4o\": 128000,\n    },\n    \"gemini\": {\n        \"gemini-pro\": 128000,\n        \"gemini-1.5-flash-latest\":128000,\n        \"gemini-1.5-pro-latest\":128000,\n        \"models/embedding-001\": 2048\n    },\n\n    \"ollama\": {\n        \"command-r\": 12800,\n        \"command-r-plus\": 12800,\n        \"codellama\": 16000,\n        \"dbrx\": 32768,\n        \"dbrx:instruct\": 32768,\n        \"deepseek-coder:33b\": 16000,\n        \"dolphin-mixtral\": 32000,\n        \"llama2\": 4096,\n        \"llama3\": 8192,\n        \"llama3:70b-instruct\": 8192,\n        \"llava\": 4096,\n        \"llava:34b\": 4096,\n        \"llava_next\": 4096,\n        \"mistral\": 8192,\n        \"falcon\": 2048,\n        \"codellama\": 16000,\n        \"dolphin-mixtral\": 32000,\n        \"mistral-openorca\": 32000,\n        \"stablelm-zephyr\": 8192,\n        \"command-r-plus\": 12800,\n        \"command-r\": 12800,\n        \"mistral:7b-instruct\": 32768,\n        \"mistral-openorca\": 32000,\n        \"mixtral:8x22b-instruct\": 65536,\n        \"nous-hermes2:34b\": 4096,\n        \"orca-mini\": 2048,\n        \"phi3:3.8b\": 12800,\n        \"phi3:14b\": 12800,\n        \"qwen:0.5b\": 32000,\n        \"qwen:1.8b\": 32000,\n        \"qwen:4b\": 32000,\n        \"qwen:14b\": 32000,\n        \"qwen:32b\": 32000,\n        \"qwen:72b\": 32000,\n        \"qwen:110b\": 32000,\n        \"stablelm-zephyr\": 8192,\n        \"wizardlm2:8x22b\": 65536,\n        # embedding models\n        \"nomic-embed-text\": 8192,\n        \"snowflake-arctic-embed:335m\": 8192,\n        \"snowflake-arctic-embed:l\": 8192,\n        \"mxbai-embed-large\": 512,\n    },\n    \"oneapi\": {\n        \"qwen-turbo\": 16380\n    },\n    \"groq\": {\n        \"llama3-8b-8192\": 8192,\n        \"llama3-70b-8192\": 8192,\n        \"mixtral-8x7b-32768\": 32768,\n        \"gemma-7b-it\": 8192,\n    },\n    \"claude\": {\n        \"claude_instant\": 100000,\n        \"claude2\": 9000,\n        \"claude2.1\": 200000,\n        \"claude3\": 200000\n    },\n    \"bedrock\": {\n        \"anthropic.claude-3-haiku-20240307-v1:0\": 200000,\n        \"anthropic.claude-3-sonnet-20240229-v1:0\": 200000,\n        \"anthropic.claude-3-opus-20240229-v1:0\": 200000,\n        \"anthropic.claude-v2:1\": 200000,\n        \"anthropic.claude-v2\": 100000,\n        \"anthropic.claude-instant-v1\": 100000,\n        \"meta.llama3-8b-instruct-v1:0\": 8192,\n        \"meta.llama3-70b-instruct-v1:0\": 8192,\n        \"meta.llama2-13b-chat-v1\": 4096,\n        \"meta.llama2-70b-chat-v1\": 4096,\n        \"mistral.mistral-7b-instruct-v0:2\": 32768,\n        \"mistral.mixtral-8x7b-instruct-v0:1\": 32768,\n        \"mistral.mistral-large-2402-v1:0\": 32768,\n\t\t# Embedding models\n\t\t\"amazon.titan-embed-text-v1\": 8000,\n\t\t\"amazon.titan-embed-text-v2:0\": 8000,\n        \"cohere.embed-english-v3\": 512,\n        \"cohere.embed-multilingual-v3\": 512\n    },\n    \"mistral\": {\n        \"mistralai/Mistral-7B-Instruct-v0.2\": 32000\n    },\n    \"hugging_face\": {\n        \"meta-llama/Meta-Llama-3-8B\": 8192,\n        \"meta-llama/Meta-Llama-3-8B-Instruct\": 8192,\n        \"meta-llama/Meta-Llama-3-70B\": 8192,\n        \"meta-llama/Meta-Llama-3-70B-Instruct\": 8192,\n        \"google/gemma-2b\": 8192,\n        \"google/gemma-2b-it\": 8192,\n        \"google/gemma-7b\": 8192,\n        \"google/gemma-7b-it\": 8192,\n        \"microsoft/phi-2\": 2048,\n        \"openai-community/gpt2\": 1024,\n        \"openai-community/gpt2-medium\": 1024,\n        \"openai-community/gpt2-large\": 1024,\n        \"facebook/opt-125m\": 2048,\n        \"petals-team/StableBeluga2\": 8192,\n        \"distilbert/distilgpt2\": 1024,\n        \"mistralai/Mistral-7B-Instruct-v0.2\": 32768,\n        \"gradientai/Llama-3-8B-Instruct-Gradient-1048k\": 1040200,\n        \"NousResearch/Hermes-2-Pro-Llama-3-8B\": 8192,\n        \"NousResearch/Hermes-2-Pro-Llama-3-8B-GGUF\": 8192,\n        \"nvidia/Llama3-ChatQA-1.5-8B\": 8192,\n        \"microsoft/Phi-3-mini-4k-instruct\": 4192,\n        \"microsoft/Phi-3-mini-128k-instruct\": 131072,\n        \"mlabonne/Meta-Llama-3-120B-Instruct\": 8192,\n        \"cognitivecomputations/dolphin-2.9-llama3-8b\": 8192,\n        \"cognitivecomputations/dolphin-2.9-llama3-8b-gguf\": 8192,\n        \"cognitivecomputations/dolphin-2.8-mistral-7b-v02\": 32768,\n        \"cognitivecomputations/dolphin-2.5-mixtral-8x7b\": 32768,\n        \"TheBloke/dolphin-2.7-mixtral-8x7b-GGUF\": 32768,\n        \"deepseek-ai/DeepSeek-V2\": 131072,\n        \"deepseek-ai/DeepSeek-V2-Chat\": 131072,\n        \"claude-3-haiku\": 200000\n    },\n    \"deepseek\": {\n        \"deepseek-chat\": 32768,\n        \"deepseek-coder\": 16384\n    },\n    \"ernie\": {\n        \"ernie-bot-turbo\": 4096,\n        \"ernie-bot\": 4096,\n        \"ernie-bot-2\": 4096,\n        \"ernie-bot-2-base\": 4096,\n        \"ernie-bot-2-base-zh\": 4096,\n        \"ernie-bot-2-base-en\": 4096,\n        \"ernie-bot-2-base-en-zh\": 4096,\n        \"ernie-bot-2-base-zh-en\": 4096,\n    }\n}\n"
    }
]