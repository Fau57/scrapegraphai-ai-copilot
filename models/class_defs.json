{
    "class OneApi": {
        "prompt": "Show me the implementation of the class OneApi class in ScrapeGraphAI",
        "answer": "\"\"\" \nOpenAI Module\n\"\"\"\nfrom langchain_openai import ChatOpenAI\n\n\nclass OneApi(ChatOpenAI):\n    \"\"\"\n    A wrapper for the OneApi class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)\n"
    },
    "class OpenAIImageToText": {
        "prompt": "Show me the implementation of the class OpenAIImageToText class in ScrapeGraphAI",
        "answer": "\"\"\"\nOpenAIImageToText Module\n\"\"\"\n\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.messages import HumanMessage\n\n\nclass OpenAIImageToText(ChatOpenAI):\n    \"\"\"\n    A wrapper for the OpenAIImageToText class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n        max_tokens (int): The maximum number of tokens to generate.\n\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config, max_tokens=256)\n\n    def run(self, image_url: str) -> str:\n        \"\"\"\n        Runs the image-to-text conversion using the provided image URL.\n\n        Args:\n            image_url (str): The URL of the image to convert.\n\n        Returns:\n            str: The text description of the image.\n        \"\"\"\n        message = HumanMessage(\n            content=[\n                {\"type\": \"text\", \"text\": \"What is this image showing\"},\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": image_url,\n                        \"detail\": \"auto\",\n                    },\n                },\n            ]\n        )\n\n        # Use the invoke method from the superclass (ChatOpenAI)\n        result = self.invoke([message]).content\n        return result\n"
    },
    "class HuggingFace": {
        "prompt": "Show me the implementation of the class HuggingFace class in ScrapeGraphAI",
        "answer": "\"\"\"\nHuggingFace Module\n\"\"\"\nfrom langchain_community.chat_models.huggingface import ChatHuggingFace\n\n\nclass HuggingFace(ChatHuggingFace):\n    \"\"\"\n    A wrapper for the HuggingFace class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)\n"
    },
    "class OpenAITextToSpeech": {
        "prompt": "Show me the implementation of the class OpenAITextToSpeech class in ScrapeGraphAI",
        "answer": "\"\"\"\nOpenAITextToSpeech Module\n\"\"\"\n\nfrom openai import OpenAI\n\n\nclass OpenAITextToSpeech:\n    \"\"\"\n    Implements a text-to-speech model using the OpenAI API.\n\n    Attributes:\n        client (OpenAI): The OpenAI client used to interact with the API.\n        model (str): The model to use for text-to-speech conversion.\n        voice (str): The voice model to use for generating speech.\n\n    Args:\n        tts_config (dict): Configuration parameters for the text-to-speech model.\n    \"\"\"\n\n    def __init__(self, tts_config: dict):\n\n        # convert model_name to model\n        self.client = OpenAI(api_key=tts_config.get(\"api_key\"))\n        self.model = tts_config.get(\"model\", \"tts-1\")\n        self.voice = tts_config.get(\"voice\", \"alloy\")\n\n    def run(self, text: str) -> bytes:\n        \"\"\"\n        Converts the provided text to speech and returns the bytes of the generated speech.\n\n        Args:\n            text (str): The text to convert to speech.\n\n        Returns:\n            bytes: The bytes of the generated speech audio.\n        \"\"\"\n        response = self.client.audio.speech.create(\n            model=self.model,\n            voice=self.voice,\n            input=text\n        )\n\n        return response.content\n"
    },
    "class Gemini": {
        "prompt": "Show me the implementation of the class Gemini class in ScrapeGraphAI",
        "answer": "\"\"\"\nGemini Module\n\"\"\"\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n\nclass Gemini(ChatGoogleGenerativeAI):\n    \"\"\"\n    A wrapper for the Gemini class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model\n                        (e.g., model=\"gemini-pro\")\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        # replace \"api_key\" to \"google_api_key\"\n        llm_config[\"google_api_key\"] = llm_config.pop(\"api_key\", None)\n        super().__init__(**llm_config)\n"
    },
    "class Groq": {
        "prompt": "Show me the implementation of the class Groq class in ScrapeGraphAI",
        "answer": "\"\"\"\nGroq Module\n\"\"\"\n\nfrom langchain_groq import ChatGroq\n\n\nclass Groq(ChatGroq):\n    \"\"\"\n    A wrapper for the Groq class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model (e.g., model=\"llama3-70b-8192\")\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)"
    },
    "class OpenAI": {
        "prompt": "Show me the implementation of the class OpenAI class in ScrapeGraphAI",
        "answer": "\"\"\" \nOpenAI Module\n\"\"\"\nfrom langchain_openai import ChatOpenAI\n\n\nclass OpenAI(ChatOpenAI):\n    \"\"\"\n    A wrapper for the ChatOpenAI class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)\n"
    },
    "class AzureOpenAI": {
        "prompt": "Show me the implementation of the class AzureOpenAI class in ScrapeGraphAI",
        "answer": "\"\"\" \nAzureOpenAI Module\n\"\"\"\nfrom langchain_openai import AzureChatOpenAI\n\n\nclass AzureOpenAI(AzureChatOpenAI):\n    \"\"\"\n    A wrapper for the AzureChatOpenAI class that provides default configuration\n    and could be extended with additional methods if needed.\n    \n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)\n"
    },
    "class DeepSeek": {
        "prompt": "Show me the implementation of the class DeepSeek class in ScrapeGraphAI",
        "answer": "\"\"\" \nDeepSeek Module\n\"\"\"\nfrom langchain_openai import ChatOpenAI\n\n\nclass DeepSeek(ChatOpenAI):\n    \"\"\"\n    A wrapper for the ChatOpenAI class (DeepSeek uses an OpenAI-like API) that\n    provides default configuration and could be extended with additional methods\n    if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)\n"
    },
    "class Anthropic": {
        "prompt": "Show me the implementation of the class Anthropic class in ScrapeGraphAI",
        "answer": "\"\"\" \nAnthropic Module\n\"\"\"\nfrom langchain_anthropic import ChatAnthropic\n\n\nclass Anthropic(ChatAnthropic):\n    \"\"\"\n    A wrapper for the ChatAnthropic class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)"
    },
    "class Ollama": {
        "prompt": "Show me the implementation of the class Ollama class in ScrapeGraphAI",
        "answer": "\"\"\" \nOllama Module\n\"\"\"\nfrom langchain_community.chat_models import ChatOllama\n\n\nclass Ollama(ChatOllama):\n    \"\"\"\n    A wrapper for the ChatOllama class that provides default configuration\n    and could be extended with additional methods if needed.\n\n    Args:\n        llm_config (dict): Configuration parameters for the language model.\n    \"\"\"\n\n    def __init__(self, llm_config: dict):\n        super().__init__(**llm_config)\n"
    },
    "class Bedrock": {
        "prompt": "Show me the implementation of the class Bedrock class in ScrapeGraphAI",
        "answer": "\"\"\" \nbedrock configuration wrapper\n\"\"\"\nfrom langchain_aws import ChatBedrock\n\n\nclass Bedrock(ChatBedrock):\n    \"\"\"Class for wrapping bedrock module\"\"\"\n\n    def __init__(self, llm_config: dict):\n        \"\"\"\n        A wrapper for the ChatBedrock class that provides default configuration\n        and could be extended with additional methods if needed.\n\n        Args:\n            llm_config (dict): Configuration parameters for the language model.\n        \"\"\"\n        # Initialize the superclass (ChatBedrock) with provided config parameters\n        super().__init__(**llm_config)\n"
    }
}