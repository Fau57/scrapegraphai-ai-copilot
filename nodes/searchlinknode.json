[
    {
      "prompt": "What is the purpose of the SearchLinkNode class in scrapegraph ai?",
      "answer": "The `SearchLinkNode` class in scrapegraph ai filters out the relevant links in the webpage content based on the user prompt. It expects the already scraped links on the webpage and is typically used after the FetchNode."
    },
    {
      "prompt": "What are the attributes of the SearchLinkNode class in scrapegraph ai?",
      "answer": "The `SearchLinkNode` class in scrapegraph ai has two attributes: `llm_model`, which is an instance of the language model client used for generating answers, and `verbose`, a boolean flag indicating whether to show print statements during execution."
    },
    {
      "prompt": "What is the role of the execute method in the SearchLinkNode class of scrapegraph ai?",
      "answer": "The `execute` method in the `SearchLinkNode` class of scrapegraph ai filters out relevant links from the webpage that are relevant to the user prompt. It takes the current state of the graph as an argument and returns the updated state with the output key containing the list of links."
    },
    {
      "prompt": "What is the purpose of the input_keys variable in the execute method of the SearchLinkNode class in scrapegraph ai?",
      "answer": "The input_keys variable in the `execute` method of the `SearchLinkNode` class in scrapegraph ai is used to interpret input keys based on the provided input expression. It helps fetch the correct data from the state using these input keys."
    },
    {
      "prompt": "What is the role of the PromptTemplate in the execute method of the SearchLinkNode class in scrapegraph ai?",
      "answer": "The `PromptTemplate` in the `execute` method of the `SearchLinkNode` class in scrapegraph ai is used to create a prompt for the language model. It takes a template string with placeholders for input variables, which are used to fill in the placeholders with the appropriate values."
    },
    {
      "prompt": "Show me the implementation of the SearchLinkNode class in scrapegraph ai.",
      "answer": "Sure, here's the implementation for the `SearchLinkNode` class in ScrapeGraphAI:\n\n```python\n\"\"\"\nSearchLinkNode Module\n\"\"\"\n\n# Imports from standard library\nfrom typing import List, Optional\nfrom tqdm import tqdm\n\n# Imports from Langchain\nfrom langchain.prompts import PromptTemplate\nfrom langchain_core.output_parsers import JsonOutputParser\nfrom langchain_core.runnables import RunnableParallel\n\nfrom ..utils.logging import get_logger\n\n# Imports from the library\nfrom .base_node import BaseNode\n\n\nclass SearchLinkNode(BaseNode):\n    \"\"\"\n    A node that can filter out the relevant links in the webpage content for the user prompt.\n    Node expects the aleready scrapped links on the webpage and hence it is expected\n    that this node be used after the FetchNode.\n\n    Attributes:\n        llm_model: An instance of the language model client used for generating answers.\n        verbose (bool): A flag indicating whether to show print statements during execution.\n\n    Args:\n        input (str): Boolean expression defining the input keys needed from the state.\n        output (List[str]): List of output keys to be updated in the state.\n        node_config (dict): Additional configuration for the node.\n        node_name (str): The unique identifier name for the node, defaulting to \"GenerateAnswer\".\n    \"\"\"\n\n    def __init__(\n        self,\n        input: str,\n        output: List[str],\n        node_config: Optional[dict] = None,\n        node_name: str = \"GenerateLinks\",\n    ):\n        super().__init__(node_name, \"node\", input, output, 1, node_config)\n\n        self.llm_model = node_config[\"llm_model\"]\n        self.verbose = (\n            False if node_config is None else node_config.get(\"verbose\", False)\n        )\n\n    def execute(self, state: dict) -> dict:\n        \"\"\"\n        Filter out relevant links from the webpage that are relavant to prompt. Out of the filtered links, also\n        ensure that all links are navigable.\n\n        Args:\n            state (dict): The current state of the graph. The input keys will be used to fetch the\n                            correct data types from the state.\n\n        Returns:\n            dict: The updated state with the output key containing the list of links.\n\n        Raises:\n            KeyError: If the input keys are not found in the state, indicating that the\n                        necessary information for generating the answer is missing.\n        \"\"\"\n\n        self.logger.info(f\"--- Executing {self.node_name} Node ---\")\n\n        # Interpret input keys based on the provided input expression\n        input_keys = self.get_input_keys(state)\n\n        user_prompt = state[input_keys[0]]\n        parsed_content_chunks = state[input_keys[1]]\n        output_parser = JsonOutputParser()\n\n        prompt_relevant_links = \"\"\"\n            You are a website scraper and you have just scraped the following content from a website.\n            Content: {content}\n            \n            You are now tasked with identifying all hyper links within the content that are potentially\n            relevant to the user task: {user_prompt}\n            \n            Assume relevance broadly, including any links that might be related or potentially useful \n            in relation to the task.\n            \n            Please list only valid URLs and make sure to err on the side of inclusion if it's uncertain \n            whether the content at the link is directly relevant.\n\n            Output only a list of relevant links in the format:\n            [\n                \"link1\",\n                \"link2\",\n                \"link3\",\n                .\n                .\n                .\n            ]\n            \"\"\"\n        relevant_links = []\n\n        for i, chunk in enumerate(\n            tqdm(\n                parsed_content_chunks,\n                desc=\"Processing chunks\",\n                disable=not self.verbose,\n            )\n        ):\n            merge_prompt = PromptTemplate(\n                template=prompt_relevant_links,\n                input_variables=[\"content\", \"user_prompt\"],\n            )\n            merge_chain = merge_prompt | self.llm_model | output_parser\n            # merge_chain = merge_prompt | self.llm_model\n            answer = merge_chain.invoke(\n                {\"content\": chunk.page_content, \"user_prompt\": user_prompt}\n            )\n            relevant_links += answer\n        state.update({self.output[0]: relevant_links})\n        return state\n```"
    }
  ]
  