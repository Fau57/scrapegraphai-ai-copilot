[
    {
        "prompt": "What is the purpose of the JSONScraperGraph class in scrapegraph ai?",
        "answer": "The `JSONScraperGraph` class in scrapegraph ai is a scraping pipeline specifically designed for JSON files. It automates the process of extracting information from JSON files using a natural language model to interpret and answer prompts."
    },
    {
        "prompt": "What are the main attributes of the JSONScraperGraph class in scrapegraph ai?",
        "answer": "The main attributes of the `JSONScraperGraph` class in scrapegraph ai are inherited from the `AbstractGraph` class, such as `prompt`, `config`, `source`, and `schema`. Additionally, it has the `input_key` attribute, which is either 'json' or 'json_dir' based on the source."
    },
    {
        "prompt": "What is the role of the _create_graph method in the JSONScraperGraph class of scrapegraph ai?",
        "answer": "The _create_graph method in the `JSONScraperGraph` class of scrapegraph ai is responsible for creating the graph of nodes representing the workflow for JSON scraping. It includes nodes for fetching the JSON data, processing it with a RAG (Retrieval-Augmented Generation) model, and generating the final answer."
    },
    {
        "prompt": "What does the run method in the JSONScraperGraph class of scrapegraph ai do?",
        "answer": "The run method in the `JSONScraperGraph` class of scrapegraph ai executes the JSON scraping process by providing the initial inputs to the graph and calling the graph's execute method. It then stores the final state and execution info and returns the answer to the prompt."
    },
    {
        "prompt": "How does the JSONScraperGraph class in scrapegraph ai handle JSON files and directories?",
        "answer": "The `JSONScraperGraph` class in scrapegraph ai determines the `input_key` attribute based on the source. If the source ends with 'json', the `input_key` is set to 'json', and if not, it is set to 'json_dir'. This `input_key` is then used to provide the correct input to the graph's fetch node."
    },
    {
        "prompt": "Can you show me the implementation for the JsonScraperGraph in Scrapegraph ai?",
        "answer": "Sure, here's the implementation for the `JsonScraperGraph` class in ScrapeGraphAI:\n\n```python\n\"\"\"\nJSONScraperGraph Module\n\"\"\"\n\nfrom typing import Optional\n\nfrom .base_graph import BaseGraph\nfrom .abstract_graph import AbstractGraph\n\nfrom ..nodes import (\n    FetchNode,\n    RAGNode,\n    GenerateAnswerNode\n)\n\n\nclass JSONScraperGraph(AbstractGraph):\n    \"\"\"\n    JSONScraperGraph defines a scraping pipeline for JSON files.\n\n    Attributes:\n        prompt (str): The prompt for the graph.\n        source (str): The source of the graph.\n        config (dict): Configuration parameters for the graph.\n        schema (str): The schema for the graph output.\n        llm_model: An instance of a language model client, configured for generating answers.\n        embedder_model: An instance of an embedding model client, \n        configured for generating embeddings.\n        verbose (bool): A flag indicating whether to show print statements during execution.\n        headless (bool): A flag indicating whether to run the graph in headless mode.\n\n    Args:\n        prompt (str): The prompt for the graph.\n        source (str): The source of the graph.\n        config (dict): Configuration parameters for the graph.\n        schema (str): The schema for the graph output.\n\n    Example:\n        >>> json_scraper = JSONScraperGraph(\n        ...     \"List me all the attractions in Chioggia.\",\n        ...     \"data/chioggia.json\",\n        ...     {\"llm\": {\"model\": \"gpt-3.5-turbo\"}}\n        ... )\n        >>> result = json_scraper.run()\n    \"\"\"\n\n    def __init__(self, prompt: str, source: str, config: dict, schema: Optional[str] = None):\n        super().__init__(prompt, config, source, schema)\n\n        self.input_key = \"json\" if source.endswith(\"json\") else \"json_dir\"\n\n    def _create_graph(self) -> BaseGraph:\n        \"\"\"\n        Creates the graph of nodes representing the workflow for web scraping.\n\n        Returns:\n            BaseGraph: A graph instance representing the web scraping workflow.\n        \"\"\"\n\n        fetch_node = FetchNode(\n            input=\"json | json_dir\",\n            output=[\"doc\", \"link_urls\", \"img_urls\"],\n        )\n        rag_node = RAGNode(\n            input=\"user_prompt & (parsed_doc | doc)\",\n            output=[\"relevant_chunks\"],\n            node_config={\n                \"llm_model\": self.llm_model,\n                \"embedder_model\": self.embedder_model\n            }\n        )\n        generate_answer_node = GenerateAnswerNode(\n            input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n            output=[\"answer\"],\n            node_config={\n                \"llm_model\": self.llm_model,\n                \"schema\": self.schema\n            }\n        )\n\n        return BaseGraph(\n            nodes=[\n                fetch_node,\n                rag_node,\n                generate_answer_node,\n            ],\n            edges=[\n                (fetch_node, rag_node),\n                (rag_node, generate_answer_node)\n            ],\n            entry_point=fetch_node\n        )\n\n    def run(self) -> str:\n        \"\"\"\n        Executes the web scraping process and returns the answer to the prompt.\n\n        Returns:\n            str: The answer to the prompt.\n        \"\"\"\n\n        inputs = {\"user_prompt\": self.prompt, self.input_key: self.source}\n        self.final_state, self.execution_info = self.graph.execute(inputs)\n\n        return self.final_state.get(\"answer\", \"No answer found.\")\n```"
    }
]
  