[
    {
        "prompt": "What is the purpose of the SpeechGraph class in scrapegraph ai?",
        "answer": "The `SpeechGraph` class in scrapegraph ai is a scraping pipeline that scrapes the web, provides an answer to a given prompt, and generates an audio file of the answer."
    },
    {
        "prompt": "What are the main attributes of the SpeechGraph class in scrapegraph ai?",
        "answer": "The main attributes of the `SpeechGraph` class in scrapegraph ai are inherited from the `AbstractGraph` class, such as `prompt`, `config`, `source`, and `schema`. Additionally, it has the `input_key` attribute, which is either 'url' or 'local_dir' based on the source."
    },
    {
        "prompt": "What is the role of the _create_graph method in the SpeechGraph class of scrapegraph ai?",
        "answer": "The `_create_graph` method in the `SpeechGraph` class of scrapegraph ai is responsible for creating the graph of nodes representing the workflow for web scraping and audio generation. It includes nodes for fetching the web page or local data, parsing it, extracting relevant information with the RAGNode, generating the final answer with the GenerateAnswerNode, and converting the answer to audio with the TextToSpeechNode."
    },
    {
        "prompt": "What does the run method in the SpeechGraph class of scrapegraph ai do?",
        "answer": "The `run` method in the `SpeechGraph` class of scrapegraph ai executes the web scraping and audio generation process by providing the initial inputs to the graph and calling the graph's execute method. It then stores the final state and execution info, saves the audio file, and returns the answer to the prompt."
    },
    {
        "prompt": "How does the SpeechGraph class in scrapegraph ai handle web pages and local directories?",
        "answer": "The `SpeechGraph` class in scrapegraph ai determines the `input_key` attribute based on the source. If the source starts with 'http', the `input_key` is set to 'url', and if not, it is set to 'local_dir'. This `input_key` is then used to provide the correct input to the graph's fetch node."
    },
    {
        "prompt": "Show me the implementation of the Speech graph (SpeechGraph) in ScrapeGraphAI.",
        "answer": "```python\n\"\"\" \nSpeechGraph Module\n\"\"\"\n\nfrom typing import Optional\n\nfrom .base_graph import BaseGraph\nfrom .abstract_graph import AbstractGraph\n\nfrom ..nodes import (\n    FetchNode,\n    ParseNode,\n    RAGNode,\n    GenerateAnswerNode,\n    TextToSpeechNode,\n)\n\nfrom ..utils.save_audio_from_bytes import save_audio_from_bytes\nfrom ..models import OpenAITextToSpeech\n\n\nclass SpeechGraph(AbstractGraph):\n    \"\"\"\n    SpeechyGraph is a scraping pipeline that scrapes the web, provide an answer to a given prompt, and generate an audio file.\n\n    Attributes:\n        prompt (str): The prompt for the graph.\n        source (str): The source of the graph.\n        config (dict): Configuration parameters for the graph.\n        schema (str): The schema for the graph output.\n        llm_model: An instance of a language model client, configured for generating answers.\n        embedder_model: An instance of an embedding model client, configured for generating embeddings.\n        verbose (bool): A flag indicating whether to show print statements during execution.\n        headless (bool): A flag indicating whether to run the graph in headless mode.\n        model_token (int): The token limit for the language model.\n\n    Args:\n        prompt (str): The prompt for the graph.\n        source (str): The source of the graph.\n        config (dict): Configuration parameters for the graph.\n        schema (str): The schema for the graph output.\n\n    Example:\n        >>> speech_graph = SpeechGraph(\n        ...     \"List me all the attractions in Chioggia and generate an audio summary.\",\n        ...     \"https://en.wikipedia.org/wiki/Chioggia\",\n        ...     {\"llm\": {\"model\": \"gpt-3.5-turbo\"}}\n    \"\"\"\n\n    def __init__(self, prompt: str, source: str, config: dict, schema: Optional[str] = None):\n        super().__init__(prompt, config, source, schema)\n\n        self.input_key = \"url\" if source.startswith(\"http\") else \"local_dir\"\n\n    def _create_graph(self) -> BaseGraph:\n        \"\"\"\n        Creates the graph of nodes representing the workflow for web scraping and audio generation.\n\n        Returns:\n            BaseGraph: A graph instance representing the web scraping and audio generation workflow.\n        \"\"\"\n\n        fetch_node = FetchNode(\n            input=\"url | local_dir\",\n            output=[\"doc\", \"link_urls\", \"img_urls\"]\n        )\n        parse_node = ParseNode(\n            input=\"doc\",\n            output=[\"parsed_doc\"],\n            node_config={\n                \"chunk_size\": self.model_token\n            }\n        )\n        rag_node = RAGNode(\n            input=\"user_prompt & (parsed_doc | doc)\",\n            output=[\"relevant_chunks\"],\n            node_config={\n                \"llm_model\": self.llm_model,\n                \"embedder_model\": self.embedder_model            }\n        )\n        generate_answer_node = GenerateAnswerNode(\n            input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n            output=[\"answer\"],\n            node_config={\n                \"llm_model\": self.llm_model,\n                \"schema\": self.schema\n            }\n        )\n        text_to_speech_node = TextToSpeechNode(\n            input=\"answer\",\n            output=[\"audio\"],\n            node_config={\n                \"tts_model\": OpenAITextToSpeech(self.config[\"tts_model\"])\n            }\n        )\n\n        return BaseGraph(\n            nodes=[\n                fetch_node,\n                parse_node,\n                rag_node,\n                generate_answer_node,\n                text_to_speech_node\n            ],\n            edges=[\n                (fetch_node, parse_node),\n                (parse_node, rag_node),\n                (rag_node, generate_answer_node),\n                (generate_answer_node, text_to_speech_node)\n            ],\n            entry_point=fetch_node\n        )\n\n    def run(self) -> str:\n        \"\"\"\n        Executes the scraping process and returns the answer to the prompt.\n\n        Returns:\n            str: The answer to the prompt.\n        \"\"\"\n        \n        inputs = {\"user_prompt\": self.prompt, self.input_key: self.source}\n        self.final_state, self.execution_info = self.graph.execute(inputs)\n\n        audio = self.final_state.get(\"audio\", None)\n        if not audio:\n            raise ValueError(\"No audio generated from the text.\")\n        save_audio_from_bytes(audio, self.config.get(\n            \"output_path\", \"output.mp3\"))\n        print(f\"Audio saved to {self.config.get('output_path', 'output.mp3')}\")\n\n        return self.final_state.get(\"answer\", \"No answer found.\")\n```"
    }
]
  