[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using groq as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper with schema\n\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nschema= \"\"\"\n    { \n    \\\"Projects\\\": [\n        \\\"Project #\\\": \n            { \n                \\\"title\\\": \\\"...\\\", \n                \\\"description\\\": \\\"...\\\", \n            }, \n        \\\"Project #\\\": \n            { \n                \\\"title\\\": \\\"...\\\", \n                \\\"description\\\": \\\"...\\\", \n            } \n        ] \n    } \n\"\"\"\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects/\",\n    schema=schema,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\nsearch_graph = SearchGraph(\n    prompt=\"List me the best escursions near Trento\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on the internet using groq as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"headless\": False\n}\n\nsearch_graph = SearchGraph(\n    prompt=\"List me the best escursions near Trento\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple websites given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraperMultiGraph\n\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperMultiGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n# *******************************************************\n# Create the SmartScraperMultiGraph instance and run it\n# *******************************************************\n\nmultiple_search_graph = SmartScraperMultiGraph(\n    prompt=\"Who is Marco Perini?\",\n    source=[\n        \"https://perinim.github.io/\",\n        \"https://perinim.github.io/cv/\"\n    ],\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using XMLScraperGraph from XML documents\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a JSON given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using JSONScraperGraph from JSON documents\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the JSON file\n# ************************************************\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the JSONScraperGraph instance and run it\n# ************************************************\n\njson_scraper_graph = JSONScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = json_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = json_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using CSVScraperGraph from CSV documents\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n}\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n\n"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using groq as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper from text\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using groq as a provider?",
        "answer": "Example of pdf_scraper_graph\n\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import PDFScraperGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"verbose\": True,\n    \"headless\": False\n}\n\n\nsource = \"\"\"\n    The Divine Comedy, Italian La Divina Commedia, original name La commedia, long narrative poem written in Italian \n    circa 1308/21 by Dante. It is usually held to be one of the world s great works of literature. \n    Divided into three major sections—Inferno, Purgatorio, and Paradiso—the narrative traces the journey of Dante \n    from darkness and error to the revelation of the divine light, culminating in the Beatific Vision of God. \n    Dante is guided by the Roman poet Virgil, who represents the epitome of human knowledge, from the dark wood \n    through the descending circles of the pit of Hell (Inferno). He then climbs the mountain of Purgatory, guided \n    by the Roman poet Statius, who represents the fulfilment of human knowledge, and is finally led by his lifelong love, \n    the Beatrice of his earlier poetry, through the celestial spheres of Paradise.\"\n\nschema = \"\"\"\n    {\n        \\\"type\\\": \\\"object\\\",\n        \\\"properties\\\": {\n            \\\"summary\\\": {\n                \\\"type\\\": \\\"string\\\"\n            },\n            \\\"topics\\\": {\n                \\\"type\\\": \\\"array\\\",\n                \\\"items\\\": {\n                    \\\"type\\\": \\\"string\\\"\n                }\n            }\n        }\n    }\n\"\"\"\n\npdf_scraper_graph = PDFScraperGraph(\n    prompt=\"Summarize the text and find the main topics\",\n    source=source,\n    config=graph_config,\n    schema=schema,\n)\nresult = pdf_scraper_graph.run()\n\nprint(json.dumps(result, indent=4))\n"
    },
   {
        "prompt": "Example of custom graph using existing nodes",
        "answer": "Example of custom graph using existing nodes\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.models import OpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\n\nload_dotenv()\n\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\"llm\": {\"model\": \"groq/gemma-7b-it\",\"api_key\": groq_key,\"temperature\": 0},\"verbose\": True,\"headless\": False}\n\nllm_model = OpenAI(graph_config[\"llm\"])\n\nrobot_node = RobotsNode(input=\"url\",output=[\"is_scrapable\"],node_config={\"llm_model\": llm_model,\"force_scraping\": True,\"verbose\": True})\n\nfetch_node = FetchNode(input=\"url | local_dir\",output=[\"doc\", \"link_urls\", \"img_urls\"],node_config={\"verbose\": True,\"headless\": True})\n\nparse_node = ParseNode(input=\"doc\",output=[\"parsed_doc\"],node_config={\"chunk_size\": 4096,\"verbose\": True})\n\nrag_node = RAGNode(input=\"user_prompt & (parsed_doc | doc)\",output=[\"relevant_chunks\"],node_config={\"llm_model\": llm_model,\"verbose\": True})\n\ngenerate_answer_node = GenerateAnswerNode(input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",output=[\"answer\"],node_config={\"llm_model\": llm_model,\"verbose\": True})\n\ngraph = BaseGraph(nodes=[robot_node,fetch_node,parse_node,rag_node,generate_answer_node],edges=[(robot_node, fetch_node),(fetch_node, parse_node),(parse_node, rag_node),(rag_node, generate_answer_node)],entry_point=robot_node)\n\nresult, execution_info = graph.execute({\"user_prompt\": \"Describe the content\",\"url\": \"https://example.com/\"})\n\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for creating script in groq?",
        "answer": "Basic example of scraping pipeline using ScriptCreatorGraph\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\ngroq_key = os.getenv(\"GROQ_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"model\": \"groq/gemma-7b-it\",\n        \"api_key\": groq_key,\n        \"temperature\": 0\n    },\n    \"library\": \"beautifulsoup\"\n}\n# ************************************************\n# Create the ScriptCreatorGraph instance and run it\n# ************************************************\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    }, 
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLS in haiku (anthopic)? ",
        "answer": ""

    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in haiku (anthopic)? ",
        "answer": ""

    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in haiku (anthopic)? ",
        "answer": ""

    }
]
