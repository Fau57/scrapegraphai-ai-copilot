[
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using hugging face as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the events, with the following fields: company_name, event_name, event_start_date, event_start_time, event_end_date, event_end_time, location, event_mode, event_category, third_party_redirect, no_of_days, time_in_hours, hosted_or_attending, refreshments_type, registration_available, registration_link\",\n    source=\"https://www.hmhco.com/event\",\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using hugging face as a provider?",
        "answer": "\"\"\"\nBasic example of scraping pipeline using SmartScraper using Azure OpenAI Key\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nschema = \"\"\"\n{\n    \"Projects\": [\n        {\n            \"title\": \"...\",\n            \"description\": \"...\"\n        },\n        {\n            \"title\": \"...\",\n            \"description\": \"...\"\n        }\n    ]\n}\n\"\"\"\n\n# required environment variable in .env\n# HUGGINGFACEHUB_API_TOKEN\nload_dotenv()\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\n# ************************************************\n# Initialize the model instances\n# ************************************************\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    source=\"https://perinim.github.io/projects/\",\n    schema=schema,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    },
        {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and searching on internet using Hugging Face as a provider?",
        "answer": "Example of Search Graph\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple websites given a prompt using Hugging Face as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper\n\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperMultiGraph\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# *******************************************************\n# Create the SmartScraperMultiGraph instance and run it\n# *******************************************************\n\nmultiple_search_graph = SmartScraperMultiGraph(\n    prompt=\"Who is Marco Perini?\",\n    source= [\n        \"https://perinim.github.io/\",\n        \"https://perinim.github.io/cv/\"\n    ],\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))"
    },
     {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using Hugging Face as a provider?",
        "answer": "Basic example of scraping pipeline using XMLScraperGraph from XML documents\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a JSON given a prompt using Hugging Face as a provider?",
        "answer": "Basic example of scraping pipeline using JSONScraperGraph from JSON documents\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the JSON file\n# ************************************************\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Create the JSONScraperGraph instance and run it\n# ************************************************\n\njson_scraper_graph = JSONScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = json_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = json_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using Hugging Face as a provider?",
        "answer": "Basic example of scraping pipeline using CSVScraperGraph from CSV documents\n\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")"
    },
     {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using hugging face as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper from text\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using hugging face as a provider?",
        "answer": "import os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import PDFScraperGraph\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\nsource = \"\"\"\n    The Divine Comedy, Italian La Divina Commedia, original name La commedia, long narrative poem written in Italian \n    circa 1308/21 by Dante. It is usually held to be one of the world s great works of literature. \n    Divided into three major sections—Inferno, Purgatorio, and Paradiso—the narrative traces the journey of Dante \n    from darkness and error to the revelation of the divine light, culminating in the Beatific Vision of God. \n    Dante is guided by the Roman poet Virgil, who represents the epitome of human knowledge, from the dark wood \n    through the descending circles of the pit of Hell (Inferno). He then climbs the mountain of Purgatory, guided \n    by the Roman poet Statius, who represents the fulfilment of human knowledge, and is finally led by his lifelong love, \n    the Beatrice of his earlier poetry, through the celestial spheres of Paradise.\n\"\"\"\n\nschema = \"\"\"\n    {\n        \"type\": \"object\",\n        \"properties\": {\n            \"summary\": {\n                \"type\": \"string\"\n            },\n            \"topics\": {\n                \"type\": \"array\",\n                \"items\": {\n                    \"type\": \"string\"\n                }\n            }\n        }\n    }\n\"\"\"\n\npdf_scraper_graph = PDFScraperGraph(\n    prompt=\"Summarize the text and find the main topics\",\n    source=source,\n    config=graph_config,\n    schema=schema,\n)\nresult = pdf_scraper_graph.run()\n\nprint(json.dumps(result, indent=4))"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using hugging face as a provider?",
        "answer": "Example of custom graph using existing nodes\n\nimport os\nfrom dotenv import load_dotenv\n\nfrom langchain_openai import OpenAIEmbeddings\nfrom scrapegraphai.models import OpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Define the graph nodes\n# ************************************************\n\nllm_model = OpenAI(graph_config[\"llm\"])\nembedder = OpenAIEmbeddings(api_key=llm_model.openai_api_key)\n\n# define the nodes for the graph\nrobot_node = RobotsNode(\n    input=\"url\",\n    output=[\"is_scrapable\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"force_scraping\": True,\n        \"verbose\": True\n    }\n)\n\nfetch_node = FetchNode(\n    input=\"url | local_dir\",\n    output=[\"doc\", \"link_urls\", \"img_urls\"],\n    node_config={\n        \"verbose\": True,\n        \"headless\": True\n    }\n)\n\nparse_node = ParseNode(\n    input=\"doc\",\n    output=[\"parsed_doc\"],\n    node_config={\n        \"chunk_size\": 4096,\n        \"verbose\": True\n    }\n)\n\nrag_node = RAGNode(\n    input=\"user_prompt & (parsed_doc | doc)\",\n    output=[\"relevant_chunks\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"embedder_model\": embedder,\n        \"verbose\": True\n    }\n)\n\ngenerate_answer_node = GenerateAnswerNode(\n    input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n    output=[\"answer\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"verbose\": True\n    }\n)\n\n# ************************************************\n# Create the graph by defining the connections\n# ************************************************\n\ngraph = BaseGraph(\n    nodes=[\n        robot_node,\n        fetch_node,\n        parse_node,\n        rag_node,\n        generate_answer_node\n    ],\n    edges=[\n        (robot_node, fetch_node),\n        (fetch_node, parse_node),\n        (parse_node, rag_node),\n        (rag_node, generate_answer_node)\n    ],\n    entry_point=robot_node\n)\n\n# ************************************************\n# Execute the graph\n# ************************************************\n\nresult, execution_info = graph.execute({\n    \"user_prompt\": \"Describe the content\",\n    \"url\": \"https://example.com/\"\n})\n\n# get the answer from the result\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and seaching on internet using hugging face as a provider and using the omniscraper?",
        "answer": "Example of Search Graph\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SearchGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\nrepo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n)\n\ngraph_config = {\n    \"llm\": {\"model_instance\": llm_model_instance},\n    \"embeddings\": {\"model_instance\": embedder_model_instance}\n}\n\n# ************************************************\n# Create the SearchGraph instance and run it\n# ************************************************\n\nsearch_graph = SearchGraph(\n    prompt=\"List me Chioggia's famous dishes\",\n    config=graph_config\n)\n\nresult = search_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = search_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json and csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for creating script in huggin face?",
        "code": "import os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\nfrom langchain_community.llms import HuggingFaceEndpoint\nfrom langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n\nload_dotenv()\n\n# Define the configuration for the graph\n\nHUGGINGFACEHUB_API_TOKEN = os.getenv('HUGGINGFACEHUB_API_TOKEN')\n\n# Initialize the model instances\n\nrepo_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n\nllm_model_instance = HuggingFaceEndpoint(\n    repo_id=repo_id, max_length=128, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n)\n\nembedder_model_instance = HuggingFaceInferenceAPIEmbeddings(\n    api_key=HUGGINGFACEHUB_API_TOKEN, model_name='sentence-transformers/all-MiniLM-l6-v2'\n)\n\n# Create the SmartScraperGraph instance and run it\n\ngraph_config = {\n    'llm': {'model_instance': llm_model_instance},\n    'embeddings': {'model_instance': embedder_model_instance}\n}\n\n# Create the ScriptCreatorGraph instance and run it\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt='List me all the projects with their description.',\n    # also accepts a string with the already downloaded HTML code\n    source='https://perinim.github.io/projects',\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# Get graph execution info\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
    }
]
