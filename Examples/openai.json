[
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"verbose\": False,\n    \"headless\": False,\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    source=\"https://perinim.github.io/projects/\",\n    config=graph_config,\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n```"
   },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and a schema using openai as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper with schema\n\n```python\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the output schema for the graph\n# ************************************************\n\nschema= \"\"\"\n    { \n    \"Projects\": [\n        \"Project #\": \n            { \n                \"title\": \"...\", \n                \"description\": \"...\", \n            }, \n        \"Project #\": \n            { \n                \"title\": \"...\", \n                \"description\": \"...\", \n            } \n        ] \n    } \n\"\"\"\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\":openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description\",\n    source=\"https://perinim.github.io/projects/\",\n    schema=schema,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(json.dumps(result, indent=4))\n```"
   },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and seaching on internet using openai as a provider?",
        "answer": "Example of Search Graph import os; from dotenv import load_dotenv; from scrapegraphai.graphs import SearchGraph; from scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info; load_dotenv(); openai_key = os.getenv(\"OPENAI_APIKEY\"); graph_config = {\"llm\": {\"api_key\": openai_key, \"model\": \"gpt-3.5-turbo\"}, \"max_results\": 2, \"verbose\": True}; search_graph = SearchGraph(prompt=\"List me Chioggia's famous dishes\", config=graph_config); result = search_graph.run(); print(result); graph_exec_info = search_graph.get_execution_info(); print(prettify_exec_info(graph_exec_info)); convert_to_csv(result, \"result\"); convert_to_json(result, \"result\")"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple websites given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraper\n\n```python\nimport os, json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperMultiGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-4\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n\n# *******************************************************\n# Create the SmartScraperMultiGraph instance and run it\n# *******************************************************\n\nmultiple_search_graph = SmartScraperMultiGraph(\n    prompt=\"Who is Marco Perini?\",\n    source= [\n        \"https://perinim.github.io/\",\n        \"https://perinim.github.io/cv/\"\n        ],\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n```"
   },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping an XML given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using XMLScraperGraph from XML documents\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"verbose\": False,\n}\n\n# ************************************************\n# Create the XMLScraperGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n```"
   },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a JSON given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using JSONScraperGraph from JSON documents\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the JSON file\n# ************************************************\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n}\n\n# ************************************************\n# Create the JSONScraperGraph instance and run it\n# ************************************************\n\njson_scraper_graph = JSONScraperGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=text,  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = json_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = json_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n```"
   },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a CSV given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using CSVScraperGraph from CSV documents\n\n```python\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n}\n\n# ************************************************\n# Create the CSVScraperGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperGraph(\n    prompt=\"List me all the last names\",\n    source=str(text),  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n```\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping plain text given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using SmartScraperGraph from text\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import SmartScraperGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Read the text file\n# ************************************************\n\nFILE_NAME = \"inputs/plain_html_example.txt\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\n# It could be also a http request using the request model\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n}\n\n# ************************************************\n# Create the SmartScraperGraph instance and run it\n# ************************************************\n\nsmart_scraper_graph = SmartScraperGraph(\n    prompt=\"List me all the projects with their description.\",\n    source=text,\n    config=graph_config\n)\n\nresult = smart_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = smart_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n```\n"
    },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping a PDF given a prompt using openai as a provider?",
        "answer": "Basic example of scraping pipeline using PDFScraperGraph\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import PDFScraperGraph\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n\n# Convert to list\nsources = [\n    \"This paper provides evidence from a natural experiment on the relationship between positive affect and productivity. We link highly detailed administrative data on the behaviors and performance of all telesales workers at a large telecommunications company with survey reports of employee happiness that we collected on a weekly basis. We use variation in worker mood arising from visual exposure to weatherâ€”the interaction between call center architecture and outdoor weather conditionsâ€”in order to provide a quasi-experimental test of the effect of happiness on productivity. We find evidence of a positive impact on sales performance, which is driven by changes in labor productivity â€“ largely through workers converting more calls into sales, and to a lesser extent by making more calls per hour and adhering more closely to their schedule. We find no evidence in our setting of effects on measures of high-frequency labor supply such as attendance and break-taking.\",\n    \"The diffusion of social media coincided with a worsening of mental health conditions among adolescents and young adults in the United States, giving rise to speculation that social media might be detrimental to mental health. In this paper, we provide quasi-experimental estimates of the impact of social media on mental health by leveraging a unique natural experiment: the staggered introduction of Facebook across U.S. colleges. Our analysis couples data on student mental health around the years of Facebook's expansion with a generalized difference-in-differences empirical strategy. We find that the roll-out of Facebook at a college increased symptoms of poor mental health, especially depression. We also find that, among students predicted to be most susceptible to mental illness, the introduction of Facebook led to increased utilization of mental healthcare services. Lastly, we find that, after the introduction of Facebook, students were more likely to report experiencing impairments to academic performance resulting from poor mental health. Additional evidence on mechanisms suggests that the results are due to Facebook fostering unfavorable social comparisons.\",\n    \"Hollywood films are generally released first in the United States and then later abroad, with  some variation in lags across films and countries. With the growth in movie piracy since the appearance of BitTorrent in 2003, films have become available through illegal piracy immediately after release in the US, while they are not available for legal viewing abroad until their foreign premieres in each country. We make use of this variation in international release lags to ask whether longer lags â€“ which facilitate more local pre-release piracy â€“ depress theatrical box office receipts, particularly after the widespread adoption of BitTorrent. We find that longer release windows are associated with decreased box office returns, even after controlling for film and country fixed effects. This relationship is much stronger in contexts where piracy is more prevalent: after BitTorrentâ€™s adoption and in heavily-pirated genres. Our findings indicate that, as a lower bound, international box office returns in our sample were at least 7% lower than they would have been in the absence of pre-release piracy. By contrast, we do not see evidence of elevated sales displacement in US box office revenue following the adoption of BitTorrent, and we suggest that delayed legal availability of the content abroad may drive the losses to piracy.\"\n    # Add more sources here\n]\n\nprompt = \"\"\"\nYou are an expert in reviewing academic manuscripts. Please analyze the abstracts provided from an academic journal article to extract and clearly identify the following elements:\n\nIndependent Variable (IV): The variable that is manipulated or considered as the primary cause affecting other variables.\nDependent Variable (DV): The variable that is measured or observed, which is expected to change as a result of variations in the Independent Variable.\nExogenous Shock: Identify any external or unexpected events used in the study that serve as a natural experiment or provide a unique setting for observing the effects on the IV and DV.\nResponse Format: For each abstract, present your response in the following structured format:\n\nIndependent Variable (IV):\nDependent Variable (DV):\nExogenous Shock:\n\nExample Queries and Responses:\n\nQuery: This paper provides evidence from a natural experiment on the relationship between positive affect and productivity. We link highly detailed administrative data on the behaviors and performance of all telesales workers at a large telecommunications company with survey reports of employee happiness that we collected on a weekly basis. We use variation in worker mood arising from visual exposure to weather the interaction between call center architecture and outdoor weather conditions in order to provide a quasi-experimental test of the effect of happiness on productivity. We find evidence of a positive impact on sales performance, which is driven by changes in labor productivity largely through workers converting more calls into sales, and to a lesser extent by making more calls per hour and adhering more closely to their schedule. We find no evidence in our setting of effects on measures of high-frequency labor supply such as attendance and break-taking.\n\nResponse:\n\nIndependent Variable (IV): Employee happiness.\nDependent Variable (DV): Overall firm productivity.\nExogenous Shock: Sudden company-wide increase in bonus payments.\n\nQuery: The diffusion of social media coincided with a worsening of mental health conditions among adolescents and young adults in the United States, giving rise to speculation that social media might be detrimental to mental health. In this paper, we provide quasi-experimental estimates of the impact of social media on mental health by leveraging a unique natural experiment: the staggered introduction of Facebook across U.S. colleges. Our analysis couples data on student mental health around the years of Facebook's expansion with a generalized difference-in-differences empirical strategy. We find that the roll-out of Facebook at a college increased symptoms of poor mental health, especially depression. We also find that, among students predicted to be most susceptible to mental illness, the introduction of Facebook led to increased utilization of mental healthcare services. Lastly, we find that, after the introduction of Facebook, students were more likely to report experiencing impairments to academic performance resulting from poor mental health. Additional evidence on mechanisms suggests that the results are due to Facebook fostering unfavorable social comparisons.\n\nResponse:\n\nIndependent Variable (IV): Exposure to social media.\nDependent Variable (DV): Mental health outcomes.\nExogenous Shock: staggered introduction of Facebook across U.S. colleges.\n\"\"\"\n\npdf_scraper_graph = PDFScraperGraph(\n    prompt=prompt,\n    source=sources[0],\n    config=graph_config\n)\nresult = pdf_scraper_graph.run()\n\nprint(result)\n```\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai a custom graph using openai as a provider?",
        "answer": "Example of custom graph using existing nodes\n\n```python\nimport os\nfrom dotenv import load_dotenv\n\nfrom langchain_openai import OpenAIEmbeddings\nfrom scrapegraphai.models import OpenAI\nfrom scrapegraphai.graphs import BaseGraph\nfrom scrapegraphai.nodes import FetchNode, ParseNode, RAGNode, GenerateAnswerNode, RobotsNode\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n        \"temperature\": 0,\n        \"streaming\": False\n    },\n}\n\n# ************************************************\n# Define the graph nodes\n# ************************************************\n\nllm_model = OpenAI(graph_config[\"llm\"])\nembedder = OpenAIEmbeddings(api_key=llm_model.openai_api_key)\n\n# define the nodes for the graph\nrobot_node = RobotsNode(\n    input=\"url\",\n    output=[\"is_scrapable\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"force_scraping\": True,\n        \"verbose\": True,\n        }\n)\n\nfetch_node = FetchNode(\n    input=\"url | local_dir\",\n    output=[\"doc\", \"link_urls\", \"img_urls\"],\n    node_config={\n        \"verbose\": True,\n        \"headless\": True,\n    }\n)\nparse_node = ParseNode(\n    input=\"doc\",\n    output=[\"parsed_doc\"],\n    node_config={\n        \"chunk_size\": 4096,\n        \"verbose\": True,\n    }\n)\nrag_node = RAGNode(\n    input=\"user_prompt & (parsed_doc | doc)\",\n    output=[\"relevant_chunks\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"embedder_model\": embedder,\n        \"verbose\": True,\n    }\n)\ngenerate_answer_node = GenerateAnswerNode(\n    input=\"user_prompt & (relevant_chunks | parsed_doc | doc)\",\n    output=[\"answer\"],\n    node_config={\n        \"llm_model\": llm_model,\n        \"verbose\": True,\n    }\n)\n\n# ************************************************\n# Create the graph by defining the connections\n# ************************************************\n\ngraph = BaseGraph(\n    nodes=[\n        robot_node,\n        fetch_node,\n        parse_node,\n        rag_node,\n        generate_answer_node,\n    ],\n    edges=[\n        (robot_node, fetch_node),\n        (fetch_node, parse_node),\n        (parse_node, rag_node),\n        (rag_node, generate_answer_node)\n    ],\n    entry_point=robot_node\n)\n\n# ************************************************\n# Execute the graph\n# ************************************************\n\nresult, execution_info = graph.execute({\n    \"user_prompt\": \"Describe the content\",\n    \"url\": \"https://example.com/\"\n})\n\n# get the answer from the result\nresult = result.get(\"answer\", \"No answer found.\")\nprint(result)\n```\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping a specific website given a prompt and seaching on internet using openai as a provider and using the omniscraper?",
        "answer": "Basic example of scraping pipeline using OmniScraper import os, json; from dotenv import load_dotenv; from scrapegraphai.graphs import OmniScraperGraph; from scrapegraphai.utils import prettify_exec_info; load_dotenv(); openai_key = os.getenv(\"OPENAI_APIKEY\"); graph_config = {\"llm\": {\"api_key\": openai_key, \"model\": \"gpt-4o\"}, \"verbose\": True, \"headless\": True, \"max_images\": 5}; omni_scraper_graph = OmniScraperGraph(prompt=\"List me all the projects with their titles and image links and descriptions.\", source=\"https://perinim.github.io/projects/\", config=graph_config); result = omni_scraper_graph.run(); print(json.dumps(result, indent=2)); graph_exec_info = omni_scraper_graph.get_execution_info(); print(prettify_exec_info(graph_exec_info))"
    },
    {
          "prompt": "How to create a script in Scrapegraphai for creating script in openai?",
          "answer": "Basic example of scraping pipeline using ScriptCreatorGraph\n\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import ScriptCreatorGraph\nfrom scrapegraphai.utils import prettify_exec_info\n\nload_dotenv()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\"\n    },\n    \"library\": \"beautifulsoup\"\n}\n\n# ************************************************\n# Create the ScriptCreatorGraph instance and run it\n# ************************************************\n\nscript_creator_graph = ScriptCreatorGraph(\n    prompt=\"List me all the projects with their description.\",\n    # also accepts a string with the already downloaded HTML code\n    source=\"https://perinim.github.io/projects\",\n    config=graph_config\n)\n\nresult = script_creator_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = script_creator_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))"
     },
   {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple XMLS in openai?",
        "answer": "Basic example of scraping pipeline using XMLScraperMultiGraph from XML documents\n\n```python\nimport os\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import XMLScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\nload_dotenv()\n\n# ************************************************\n# Read the XML file\n# ************************************************\n\nFILE_NAME = \"inputs/books.xml\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\":openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n    \"verbose\": True,\n    \"headless\": False,\n}\n# ************************************************\n# Create the XMLScraperMultiGraph instance and run it\n# ************************************************\n\nxml_scraper_graph = XMLScraperMultiGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=[text, text],  # Pass the content of the file, not the file object\n    config=graph_config\n)\n\nresult = xml_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = xml_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n```\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple CSVs in openai ?",
        "answer": "Basic example of scraping pipeline using CSVScraperMultiGraph from CSV documents\n\n```python\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\nfrom scrapegraphai.graphs import CSVScraperMultiGraph\nfrom scrapegraphai.utils import convert_to_csv, convert_to_json, prettify_exec_info\n\nload_dotenv()\n# ************************************************\n# Read the CSV file\n# ************************************************\n\nFILE_NAME = \"inputs/username.csv\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\ntext = pd.read_csv(file_path)\n\n# ************************************************\n# Define the configuration for the graph\n# ************************************************\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": \"***************************\",\n        \"model\": \"oneapi/qwen-turbo\",\n        \"base_url\": \"http://127.0.0.1:3000/v1\",  # 设置 OneAPI URL\n    }\n}\n\n# ************************************************\n# Create the CSVScraperMultiGraph instance and run it\n# ************************************************\n\ncsv_scraper_graph = CSVScraperMultiGraph(\n    prompt=\"List me all the last names\",\n    source=[str(text), str(text)],\n    config=graph_config\n)\n\nresult = csv_scraper_graph.run()\nprint(result)\n\n# ************************************************\n# Get graph execution info\n# ************************************************\n\ngraph_exec_info = csv_scraper_graph.get_execution_info()\nprint(prettify_exec_info(graph_exec_info))\n\n# Save to json or csv\nconvert_to_csv(result, \"result\")\nconvert_to_json(result, \"result\")\n```\n"
    },
    {
        "prompt": "How to create a script in Scrapegraphai for scraping multiple JSONs in openai (anthopic)?",
        "answer": "Module for showing how PDFScraper multi works\n\n```python\nimport os\nimport json\nfrom dotenv import load_dotenv\nfrom scrapegraphai.graphs import JSONScraperMultiGraph\n\nload_dotenv()\n\nopenai_key = os.getenv(\"OPENAI_APIKEY\")\n\ngraph_config = {\n    \"llm\": {\n        \"api_key\": openai_key,\n        \"model\": \"gpt-3.5-turbo\",\n    },\n}\n\nFILE_NAME = \"inputs/example.json\"\ncurr_dir = os.path.dirname(os.path.realpath(__file__))\nfile_path = os.path.join(curr_dir, FILE_NAME)\n\nwith open(file_path, 'r', encoding=\"utf-8\") as file:\n    text = file.read()\n\nsources = [text, text]\n\nmultiple_search_graph = JSONScraperMultiGraph(\n    prompt=\"List me all the authors, title and genres of the books\",\n    source=sources,\n    schema=None,\n    config=graph_config\n)\n\nresult = multiple_search_graph.run()\nprint(json.dumps(result, indent=4))\n```\n"
    }
]
